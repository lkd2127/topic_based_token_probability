# Topic based token probability

The goal of this use case is to compute the probability of a specific token or sequence of tokens appearing across various predefined topics in a textual corpus. This probability is calculated based on the relative frequency of the token(s) appearing within the corpus of each topic as well as the overall corpus.

**Calculation Method:**
P(token)= count of token(s) / total number of token(s) in the corpus <br>

[The data used in the use case](https://drive.google.com/drive/folders/17F58v0khyJI3ATwPT7PI4zq8dFrlT5wr?usp=drive_link)
​

**This use case is particularly useful for:**
- *Topic Modeling*: Understanding which words are strongly associated with certain topics in a corpus.
- *Text Classification*: Helping classify new texts based on the likelihood that they contain certain words or sequences of words associated with specific topics.
- *Text Analysis*: Providing insights into the distribution of specific topics or keywords across different categories of content.
